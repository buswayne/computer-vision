# -*- coding: utf-8 -*-
"""BUSETTO_Assignment3.ipynb

Automatically generated by Colaboratory.

# GENERATOR AND DISCRIMINATOR DEFINITION
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import torchvision

# It takes quite long time to train a GAN, better to save the snapshots/final model in your drive.
# Mount GoogleDrive here.
from google.colab import drive
drive.mount('/content/gdrive/')

# Check everything going well
# !ls /content/gdrive/'My Drive'

# Define some hyper parameters
epo_size  = 200
bch_size  = 100    # batch size
base_lr   = 0.0001 # learning rate
mnist_dim = 784    # =28x28, 28 is the height/width of a mnist image.
z_dim     = 100    # dimension of the random vector z for Generator's input.
save_root = F"/content/gdrive/My Drive/"  # where to save your models.


# Define transform func.
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])])

# Define dataloader
train_dataset = datasets.MNIST(root='./mnist_data/', train=True,  transform=transform, download=True )
test_dataset  = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)
train_loader  = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bch_size, shuffle=True )
test_loader   = torch.utils.data.DataLoader(dataset= test_dataset, batch_size=bch_size, shuffle=False)

# Define the two networks
class Generator(nn.Module):
    def __init__(self, g_input_dim=100, g_output_dim=784):
        super(Generator, self).__init__()       
        self.fc1 = nn.Linear(g_input_dim, 256)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)
        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)
    
    # forward method
    def forward(self, x): 
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.leaky_relu(self.fc3(x), 0.2)
        return torch.tanh(self.fc4(x))
    
class Discriminator(nn.Module):
    def __init__(self, d_input_dim=784):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(d_input_dim, 1024)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)
        self.fc4 = nn.Linear(self.fc3.out_features, 1)
    
    # forward method
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc3(x), 0.2)
        x = F.dropout(x, 0.3)
        return torch.sigmoid(self.fc4(x))

# Initialize a Generator and a Discriminator. 
G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).cuda()
D = Discriminator(mnist_dim).cuda()

# Loss func. BCELoss means Binary Cross Entropy Loss.
criterion = nn.BCELoss() 

# Initialize the optimizer. Use Adam.
G_optimizer = optim.Adam(G.parameters(), lr = base_lr)
D_optimizer = optim.Adam(D.parameters(), lr = base_lr)

# Code for training the discriminator.
def D_train(x, D_optimizer):
    D_optimizer.zero_grad()
    b,c,h,w = x.size()

    # train discriminator on real image
    x_real, y_real = x.view(-1, mnist_dim), torch.ones(b, 1)
    x_real, y_real = Variable(x_real).cuda(), Variable(y_real).cuda()

    D_output = D(x_real)
    D_real_loss = criterion(D_output, y_real)
    D_real_score = D_output

    # train discriminator on fake
    z      = Variable(torch.randn(b, z_dim)).cuda()
    y_fake = Variable(torch.zeros(b, 1)).cuda()
    x_fake = G(z)

    D_output = D(x_fake.detach()) # Detach the x_fake, no need grad. for Generator.
    D_fake_loss = criterion(D_output, y_fake)
    D_fake_score = D_output

    # Only update D's parameters
    D_loss = D_real_loss + D_fake_loss
    D_loss.backward()
    D_optimizer.step()
        
    return  D_loss.data.item()

# Code for training the generator
def G_train(bch_size, z_dim, G_optimizer):
    G_optimizer.zero_grad()

    z = Variable(torch.randn(bch_size, z_dim)).cuda()
    y = Variable(torch.ones(bch_size, 1)).cuda()

    G_output = G(z)
    D_output = D(G_output)
    G_loss = criterion(D_output, y) # Fool the discriminator :P

    # Only update G's parameters
    G_loss.backward()
    G_optimizer.step()
        
    return G_loss.data.item(), G_output

import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output, display

def Logging(images, G_loss, D_loss):
    clear_output(wait=True)
    plt.clf()
    x_values = np.arange(0,len(G_loss), 1)
    fig, ax = plt.subplots()
    ax.plot(G_loss, label='G_loss')
    ax.plot(D_loss, label='D_loss')
    legend = ax.legend(loc='upper right', shadow=True, fontsize='x-large')
    plt.grid(linestyle='-')
    plt.title("Training loss")
    plt.ylabel("Loss")
    plt.show()
    show_imgs = torchvision.utils.make_grid(G_output, nrow=10).numpy().transpose((1,2,0))
    plt.imshow(show_imgs) 
    plt.show()

D_epoch_losses, G_epoch_losses = [], []   # record the average loss per epoch.
for epoch in range(1, epo_size+1):
    D_losses, G_losses = [], []     
    for iteration, (x, _) in enumerate(train_loader):
        # Train discriminator 
        D_loss = D_train(x, D_optimizer)
        D_losses.append(D_loss)
        # Train generator
        G_loss, G_output = G_train(bch_size, z_dim, G_optimizer)
        G_losses.append(G_loss)

    # Record losses for logging
    D_epoch_loss = torch.mean(torch.FloatTensor(D_losses))
    G_epoch_loss = torch.mean(torch.FloatTensor(G_losses))
    D_epoch_losses.append(D_epoch_loss)
    G_epoch_losses.append(G_epoch_loss)

    # Convert G_output to an image.
    G_output = G_output.detach().cpu()
    G_output = G_output.view(-1, 1, 28, 28)

    # Logging 
    Logging(G_output, G_epoch_losses, D_epoch_losses)
    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (
            (epoch), epo_size, D_epoch_loss, G_epoch_loss))
    
    # Save G/D models
    save_pth_G = save_root+'G_model.pt'
    save_pth_D = save_root+'D_model.pt'
    torch.save(G.state_dict(), save_pth_G)
    torch.save(D.state_dict(), save_pth_D)
print("Training is finished.")

"""# PART I of the assignment"""

# Lets evaluate (have fun with) the Generative model!
import os

# Load the pretrained model for G
# - First check if the path is correct
os.path.isfile(save_root+'G_model.pt')

# - Load pretrained G. 
G.load_state_dict(torch.load(save_root+'G_model.pt'))
G.eval()

# Run this block many times to generate random digit images.
# Generate first random digit!

z1 = Variable(torch.randn(1, z_dim)).cuda()

# see z, you should see a random vector
print(z1) 
plt.hist(z1.cpu().numpy().flat, bins=20)
plt.show()

# Generate img from z1
img_vec = G(z1)
img = img_vec.view(1, 28, 28).data.cpu()
img = torchvision.utils.make_grid(img, nrow=1).numpy().transpose((1,2,0))
plt.imshow(img)

################################################################################
########## RUN THIS CELL ONLY IF YOU WANT TO OVERWRITE z2 !! ###################
################################################################################

# save z1 corresponding to digit 1
  save_pth_z1 = save_root+'z1.pt'
  torch.save(z1, save_pth_z1)

# Generate second random digit!

z2 = Variable(torch.randn(1, z_dim)).cuda()

# see z, you should see a random vector
print(z2) 
plt.hist(z2.cpu().numpy().flat, bins=20)
plt.show()

# Generate img form z
img_vec = G(z2)
img = img_vec.view(1, 28, 28).data.cpu()
img = torchvision.utils.make_grid(img, nrow=1).numpy().transpose((1,2,0))
plt.imshow(img)

################################################################################
########## RUN THIS CELL ONLY IF YOU WANT TO OVERWRITE z2 !! ###################
################################################################################

# save z2 corresponding to digit 2
  save_pth_z2 = save_root+'z2.pt'
  torch.save(z2, save_pth_z2)

# Generate vector z as weighted sum between z1 and z2
# plot the resulting digit for values from a = 0 to 1

z1 = torch.load(save_root+'z1.pt')
z2 = torch.load(save_root+'z2.pt')
for i in torch.range(0, 10):
  a = i/10
  scaling = i.item()/10
  print('Current value of a:', scaling)
  z = a*z1 + (1-a)*z2
  
  # see z, you should see a random vector
  print(z) 
  plt.hist(z.cpu().numpy().flat, bins=20)
  plt.show()

  # Generate img form z
  img_vec = G(z)
  img = img_vec.view(1, 28, 28).data.cpu()
  img = torchvision.utils.make_grid(img, nrow=1).numpy().transpose((1,2,0))
  plt.imshow(img)
  plt.show()

# ADD ANOTHER DIGIT

z3 = Variable(torch.randn(1, z_dim)).cuda()

# see z, you should see a random vector
print(z3) 
plt.hist(z3.cpu().numpy().flat, bins=20)
plt.show()

# Generate img from z3
img_vec = G(z3)
img = img_vec.view(1, 28, 28).data.cpu()
img = torchvision.utils.make_grid(img, nrow=1).numpy().transpose((1,2,0))
plt.imshow(img)

### save z3 corresponding to digit 1
  save_pth_z3 = save_root+'z3.pt'
  torch.save(z3, save_pth_z3)

# Run this block many times to generate random digit images.
# Have fun!

z3 = torch.load(save_root+'z3.pt')
for i in torch.range(0, 10):
  a = i/10
  scaling = i.item()/10
  print('Current value of a:', scaling)
  z = a*z1 + (abs(0.5-a))*z2 + (1-a)*z3


  # see z, you should see a random vector
  print(z) 
  plt.hist(z.cpu().numpy().flat, bins=20)
  plt.show()

  # Generate img form z
  img_vec = G(z)
  img = img_vec.view(1, 28, 28).data.cpu()
  img = torchvision.utils.make_grid(img, nrow=1).numpy().transpose((1,2,0))
  plt.imshow(img)
  plt.show()

"""# PART II of the assignment

TRAIN THE NETWORK FOR CLASSIFICATION FIRST, THEN EVALUATE LATENT SPACE FOR 1000 AND 10000 Z'S

### NETWORK FOR CLASSIFICATION:
### 3fcl_512_512_BATCHNORM_SGD_60000
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

# Hyperparameters
num_epochs = 4
num_classes = 10
learning_rate = 0.001
input_dimension = 1
output_dimension = 10

# LOAD DATASET
from   torchvision import datasets as datasets
import torchvision.transforms as transforms
import torch.utils as utils
import matplotlib.pyplot as plt
import torch
import torchvision

trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
train_dataset = datasets.MNIST('./data', train=True,  download=True, transform=trans)
test_dataset  = datasets.MNIST('./data', train=False, download=True, transform=trans)
train_loader = utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)
test_loader  = utils.data.DataLoader(test_dataset, batch_size=100, shuffle=True, num_workers=2)

# CREATE THE MODEL
class simple_network(nn.Module):
  def __init__(self):
    super(simple_network, self).__init__()

# Fully connected layers
    self.fc1 = nn.Linear(784, 512)
    self.bn1 = nn.BatchNorm1d(512) #batch normalization
    self.fc2 = nn.Linear(512, 512)
    self.bn2 = nn.BatchNorm1d(512) #batch normalization
    self.fc3 = nn.Linear(512, num_classes)
       
  def forward(self, x): 
    b,c,h,w = x.size()                  # batch, channels, height, width
    x = x.view(b, -1)                   # flatten the tensor x
    x = F.relu(self.fc1(x))
    x = self.bn1(x)
    x = F.relu(self.fc2(x))
    x = self.bn2(x)
    x = self.fc3(x)
    return  F.log_softmax(x, 1)

# LOSS FUCTION AND OPTIMIZER
model = simple_network().cuda()
import torch.optim as optim
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)
print(model)

# TRAIN THE MODEL
total_step = len(train_loader)
loss_list = []
acc_list = []
for epoch in range(num_epochs):     # loop over the dataset multiple times
  running_loss = 0.0
  ct_num = 0
  for i, (images, labels) in enumerate(train_loader):
    # Run the forward pass
    images = images.cuda()
    labels = labels.cuda()
    
    # Backprop and perform Adam optimization
    optimizer.zero_grad()
    
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
    loss_list.append(loss.item())
    
    # Print statistics
    running_loss += loss.item()
    ct_num += 1
    if (i + 1) % 100 == 0:
      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
            .format(epoch + 1, num_epochs, i + 1, total_step, running_loss/ct_num))
      
print('Finished training')

# TEST THE MODEL
accuracy = []
model.eval()
with torch.no_grad():
  correct = 0
  total = 0
  for images, labels in test_loader:
    images = images.cuda()
    labels = labels.cuda()
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
    accuracy.append((correct / total)*100)
    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))

print('Accuracy of the model: {} %'.format(np.mean(accuracy)))

"""## 1000 z's (NORMAL DISTRIBUTED)"""

# Model Validation
classes = []
def evaluate_model(zvalue):
  model.eval()
  # Move inputs and labels into GPU
  inputs = zvalue.cuda()
  # Forward
  outputs = model(inputs)
  # Get predicted classes
  _, pred_cls = torch.max(outputs, 1)
  classes.append(pred_cls.item())

# Generate 1000 random images with z = 100 
max_iter = 1000
b = []
z_vec = []
classes = []
i = 0
for i in range(max_iter):
  z = Variable(torch.randn(1, z_dim)).cuda()
  #plt.hist(z.cpu().numpy().flat, bins=20)
  # Generate img from z
  img_vec = G(z)
  img_val = img_vec.view(1,28,28)
  img_val = img_val[None,:,:,:]
  evaluate_model(img_val)
  #print(labels[i].item())
  z = z.cpu().numpy()
  z_vec.append(z) 
  img_vec = img_vec.cpu()
  img = img_vec.detach().numpy()
  b.append(img)
  if(i%100 == 0):
    print('Iteration: [',i,'/',max_iter,']')
  i+=1

# Convert tensors to arrays
import numpy
z_vec = numpy.asarray(z_vec)
b = numpy.asarray(b)
y = numpy.asarray(classes)
print(y.shape)
z_vec.flatten()
z_vec = z_vec[:, 0, :]
type(z_vec)
print(z_vec.shape)
b.flatten()
b = b[:, 0, :]
type(b)
print(b.shape)

from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)

# Convert the image to a numpy array

X_z_2d = tsne.fit_transform(z_vec)
print(X_z_2d.shape)
X_b_2d = tsne.fit_transform(b)
print(X_b_2d.shape)

# Plot z's
from matplotlib import pyplot as plt
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_z_2d[y == i, 0], X_z_2d[y == i, 1], s=15, c=c, label=label)
plt.legend()
plt.show()

# Plot data
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_b_2d[y == i, 0], X_b_2d[y == i, 1], s=15, c=c, label=label)
plt.legend()
plt.show()

"""## 10000 z's (NORMAL DISTRIBUTED)"""

# Model Validation
classes = []
def evaluate_model(zvalue):
  model.eval()
  # Move inputs and labels into GPU
  inputs = zvalue.cuda()
  # Forward
  outputs = model(inputs)
  # Get predicted classes
  _, pred_cls = torch.max(outputs, 1)
  classes.append(pred_cls.item())

# Generate 1000 random images with z = 100 
max_iter = 10000
b = []
z_vec = []
classes = []
i = 0
for i in range(max_iter):
  z = Variable(torch.randn(1, z_dim)).cuda()
  #plt.hist(z.cpu().numpy().flat, bins=20)
  # Generate img from z
  img_vec = G(z)
  img_val = img_vec.view(1,28,28)
  img_val = img_val[None,:,:,:]
  evaluate_model(img_val)
  #print(labels[i].item())
  z = z.cpu().numpy()
  z_vec.append(z) 
  img_vec = img_vec.cpu()
  img = img_vec.detach().numpy()
  b.append(img)
  if(i%100 == 0):
    print('Iteration: [',i,'/',max_iter,']')
  i+=1

import numpy
z_vec = numpy.asarray(z_vec)
b = numpy.asarray(b)
y = numpy.asarray(classes)
print(y.shape)
z_vec.flatten()
z_vec = z_vec[:, 0, :]
type(z_vec)
print(z_vec.shape)
b.flatten()
b = b[:, 0, :]
type(b)
print(b.shape)

from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)

# Convert the image to a numpy array

X_z_2d = tsne.fit_transform(z_vec)
print(X_z_2d.shape)
X_b_2d = tsne.fit_transform(b)
print(X_b_2d.shape)

# Plot z's
from matplotlib import pyplot as plt
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_z_2d[y == i, 0], X_z_2d[y == i, 1], s=8, c=c, label=label)
plt.legend()
plt.show()

# Plot data
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_b_2d[y == i, 0], X_b_2d[y == i, 1], s=8, c=c, label=label)
plt.legend()
plt.show()

"""## 1000 'z (UNIFORMLY DISTRIBUTED)"""

# Model Validation
classes = []
def evaluate_model(zvalue):
  model.eval()
  # Move inputs and labels into GPU
  inputs = zvalue.cuda()
  # Forward
  outputs = model(inputs)
  # Get predicted classes
  _, pred_cls = torch.max(outputs, 1)
  classes.append(pred_cls.item())

# Generate 1000 random images with z = 100 
max_iter = 1000
b = []
z_vec = []
classes = []
i = 0
for i in range(max_iter):
  z = Variable(torch.from_numpy(np.random.uniform(0,1,[1,z_dim])).float()).cuda()
  #plt.hist(z.cpu().numpy().flat, bins=20)
  # Generate img from z
  img_vec = G(z)
  img_val = img_vec.view(1,28,28)
  img_val = img_val[None,:,:,:]
  evaluate_model(img_val)
  #print(labels[i].item())
  z = z.cpu().numpy()
  z_vec.append(z) 
  img_vec = img_vec.cpu()
  img = img_vec.detach().numpy()
  b.append(img)
  if(i%100 == 0):
    print('Iteration: [',i,'/',max_iter,']')
  i+=1

import numpy
z_vec = numpy.asarray(z_vec)
b = numpy.asarray(b)
y = numpy.asarray(classes)
print(y.shape)
z_vec.flatten()
z_vec = z_vec[:, 0, :]
type(z_vec)
print(z_vec.shape)
b.flatten()
b = b[:, 0, :]
type(b)
print(b.shape)

from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)

# Convert the image to a numpy array

X_z_2d = tsne.fit_transform(z_vec)
print(X_z_2d.shape)
X_b_2d = tsne.fit_transform(b)
print(X_b_2d.shape)

# Plot z's
from matplotlib import pyplot as plt
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_z_2d[y == i, 0], X_z_2d[y == i, 1], s=8, c=c, label=label)
plt.legend()
plt.show()

# Plot data
target_ids = range(10)
plt.figure(figsize=(6, 5))
target_names = np.array([0, 1, 2,3,4,5,6,7,8,9])
print(target_names)
colors = 'k', 'b', 'y', 'r', 'g', 'm', 'c', 'orange', 'purple', 'brown'
for i, c, label in zip(target_ids, colors, target_names):
    plt.scatter(X_b_2d[y == i, 0], X_b_2d[y == i, 1], s=8, c=c, label=label)
plt.legend()
plt.show()
